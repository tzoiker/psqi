{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Use CPU if no GPU\n",
    "# os.environ['PSQI_DEVICE'] = 'cuda:1'\n",
    "os.environ['PSQI_DEVICE'] = 'cpu'\n",
    "os.environ['PSQI_RESULTS_DIR'] = os.path.join(os.getcwd(), 'results')\n",
    "os.environ['PSQI_DATA_DIR'] = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psqi.preprocess import parse_raw_data, scale_data, _get_y_limits\n",
    "\n",
    "df_all, df_X, df_Y, norms = parse_raw_data()\n",
    "X, Y, X_scaler, Y_scaler, scaled_norms = scale_data(df_X, df_Y, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {'rank': 3, 'num_mixtures': 1, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 5, 'num_mixtures': 1, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 7, 'num_mixtures': 1, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 10, 'num_mixtures': 1, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 15, 'num_mixtures': 1, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 3, 'num_mixtures': 2, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 5, 'num_mixtures': 2, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 7, 'num_mixtures': 2, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 10, 'num_mixtures': 2, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 15, 'num_mixtures': 2, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 3, 'num_mixtures': 3, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 5, 'num_mixtures': 3, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 7, 'num_mixtures': 3, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 10, 'num_mixtures': 3, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 15, 'num_mixtures': 3, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 3, 'num_mixtures': 4, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 5, 'num_mixtures': 4, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 7, 'num_mixtures': 4, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 10, 'num_mixtures': 4, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 15, 'num_mixtures': 4, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 3, 'num_mixtures': 5, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 5, 'num_mixtures': 5, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 7, 'num_mixtures': 5, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 10, 'num_mixtures': 5, 'n_splits': 5, 'max_iter': 100},\n",
    "    {'rank': 15, 'num_mixtures': 5, 'n_splits': 5, 'max_iter': 100},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipypb import track\n",
    "from psqi.experiment import run_experiment\n",
    "\n",
    "for kwargs in track(params, total=len(params)):\n",
    "    print(kwargs)\n",
    "    run_experiment(X=X, Y=Y, X_scaler=X_scaler, Y_scaler=Y_scaler, **kwargs, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psqi.experiment import read_results_and_models, get_results_R2_per_params\n",
    "\n",
    "results, models = read_results_and_models(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 score for each model averaged across every split and parameter\n",
    "R2 = {\n",
    "    key: np.array([\n",
    "        entry['R2_orig'] \n",
    "        for entry in entries\n",
    "    ])\n",
    "    for key, entries in results.items()\n",
    "}\n",
    "results_R2_per_params = get_results_R2_per_params(R2=R2, params=params, y_columns=df_Y.columns)\n",
    "results_R2_per_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all elements, which have maximum R2-score across all of the models less than 0\n",
    "predicted_well = np.where(results_R2_per_params.iloc[:, 1:].max(axis=1) >= 0)[0]\n",
    "predicted_well_cols = results_R2_per_params.iloc[:, 0][predicted_well]\n",
    "print('Well-predicted params', list(predicted_well_cols))\n",
    "R2_good = {\n",
    "    k: v[:, predicted_well]\n",
    "    for k,v in R2.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) For each model and each parameter compute average R^2 across all splits\n",
    "# 2) For each model compute average R^2 across all well-predicted parameters\n",
    "R2_per_models = np.array([v.mean(axis=0) for v in R2_good.values()]).mean(axis=1)\n",
    "results_R2_per_models = pd.DataFrame()\n",
    "results_R2_per_models['R2'] = R2_per_models.round(3)\n",
    "ranks = [kwargs['rank'] for kwargs in params]\n",
    "qs = [kwargs['num_mixtures'] for kwargs in params]\n",
    "results_R2_per_models['r'] = ranks\n",
    "results_R2_per_models['Q'] = qs\n",
    "results_R2_per_models['#'] = results_R2_per_models.index.astype(int)\n",
    "scores = results_R2_per_models['R2']\n",
    "\n",
    "results_R2_per_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psqi.experiment import get_key, get_dir\n",
    "import dill as pickle\n",
    "\n",
    "# Choose the best combination of parameters (rank and number of mixtures)\n",
    "best_kwargs = params[np.argmax(scores)]\n",
    "best_key = get_key(**best_kwargs, split=None)\n",
    "print('Best parameters', best_kwargs)\n",
    "best_R2 = np.array([\n",
    "    result['R2']\n",
    "    for result in results[best_key]\n",
    "])\n",
    "# Choose the best split for this model\n",
    "best_split = np.argmax(np.array(best_R2).mean(axis=1))\n",
    "best_dir = get_dir(**best_kwargs, split=best_split)\n",
    "with open(best_dir + '/ix.pickle', 'rb') as fin:\n",
    "    best_ix = pickle.load(fin)\n",
    "\n",
    "# Get the best model\n",
    "best_model = models[best_key][best_split]['model']\n",
    "best_likelihood = models[best_key][best_split]['likelihood'] \n",
    "\n",
    "best_covar = best_model.covar_module.task_covar_module.covar_matrix.numpy()\n",
    "best_mk = best_model.covar_module.data_covar_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model estimated noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise is measured with interquartile range relative to the normative range\n",
    "\n",
    "best_noise = best_likelihood.noise_covar.noise.detach().cpu().numpy()\n",
    "best_noise = np.sqrt(best_noise) * 0.6745 * 2\n",
    "best_noise = best_noise / np.diff(scaled_norms).flatten() * 100\n",
    "inds = np.argsort(best_R2.mean(axis=0))\n",
    "df_noise = pd.DataFrame(best_noise[inds], columns=['noise, %'], index=np.array(df_Y.columns)[inds])\n",
    "df_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = pd.DataFrame()\n",
    "best_results['R2-mean'] = best_R2.mean(axis=0).round(3)\n",
    "best_results['R2-std'] = best_R2.std(axis=0).round(3)\n",
    "best_results['Y-mean'] = Y.mean(axis=0)\n",
    "best_results['Y-std'] = Y.std(axis=0)\n",
    "best_results.index = df_Y.columns.tolist()\n",
    "best_results = best_results.sort_values('R2-mean').iloc[::-1]\n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14,7))\n",
    "t = np.arange(21)\n",
    "inds = np.argsort(best_R2.mean(axis=0))\n",
    "R2_sorted = best_R2[:, inds]\n",
    "mean = R2_sorted.mean(axis=0)\n",
    "mn = R2_sorted.min(axis=0, keepdims=True)\n",
    "mx = R2_sorted.max(axis=0, keepdims=True)\n",
    "plt.plot([-10, 30], [0, 0], '--', color='black')\n",
    "plt.boxplot(\n",
    "    R2_sorted, whis=[0, 100], widths=0.6,\n",
    "    whiskerprops={'linewidth': 1.4},\n",
    "    capprops={'linewidth': 1.4},\n",
    "    boxprops={'linewidth': 1.4}\n",
    ")\n",
    "plt.xticks(ticks=t+1, labels=np.array(df_Y.columns)[inds], rotation=45, fontsize=16)\n",
    "plt.yticks(np.linspace(-0.4, 1, 15), fontsize=16)\n",
    "plt.ylim([-0.5, 1])\n",
    "plt.xlim([0, 22])\n",
    "plt.ylabel('$R^2$', fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psqi.predict import parse_geojson, compute_test_points, read_test_points, compute_predictions, save_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geojson to reduce the grid to the region of interest\n",
    "shp = parse_geojson('data/new_moscow.json', X_scaler=X_scaler)\n",
    "\n",
    "# Compute grid of points within the region of interest with a given cell size in meters\n",
    "test_X = compute_test_points(cell_size_m=10*1000, shp=shp, X_scaler=X_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid computations again, read them from file instead\n",
    "# test_X = read_test_points(10*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s = compute_predictions(model=best_model, likelihood=best_likelihood, test_X=test_X)\n",
    "df_pred = save_predictions(u=u, s=s, test_X=test_X, X_scaler=X_scaler, Y_scaler=Y_scaler, y_columns=df_Y.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating PSQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psqi.psqi import calc_psqi, save_psqi\n",
    "\n",
    "psqi, conf, ws = calc_psqi(\n",
    "    u=u, s=s, \n",
    "    norms=scaled_norms, \n",
    "    R2=best_R2,\n",
    "    df_Y=df_Y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psqi = save_psqi(psqi=psqi, conf=conf, ws=ws, test_X=test_X, X_scaler=X_scaler)\n",
    "df_psqi.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "psqi",
   "language": "python",
   "name": "psqi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
